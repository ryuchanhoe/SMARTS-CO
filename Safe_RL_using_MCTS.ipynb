{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "# from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial values\n",
    "action_space = [(-3, True), (-1, True), (0, True), (1, True), (2, True), (-3, False) (-1, False), (0, False),(1, False), (2, False)] # discrete action space; (acceleration, lane change)\n",
    "n_actions = 8 # number of actions\n",
    "n_features = 4  # number of features in state [current, prev_1, prev_2, prev_3]\n",
    "len = 1000 # length of a lane\n",
    "num_lane = 2 # number of lanes\n",
    "Road = [i for i in range(num_lane)]\n",
    "\n",
    "init_v_auto = 10 # initial velocity of agent\n",
    "init_v_v1 = [5, 8] # initial velocity of vehicle 1; randomly chosen\n",
    "init_v_v2 = [10, 15] # initial velocity of vehicle 2; randomly chosen\n",
    "init_v_v3 = [8, 13] # initial velocity of vehicle 3; randomly chosen\n",
    "init_gap_AuV1 = [30, 50] # initial gap between agent and vehicle 1; randomly chosen\n",
    "init_gap_AuV2 = [60, 200] # initial gap between agent and vehicle 2; randomly chosen\n",
    "init_gap_V2V3 = [40, 340] # initial gap between vehicle 2 and vehicle 3; randomly chosen\n",
    "\n",
    "time_step = 0.5 # time step\n",
    "\n",
    "T = 40 # Total simulation time for MCTS??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature(object): # abstract feature of environment\n",
    "    def __init__(self, s_e, s_ov):\n",
    "        self.s_e = s_e # (velocity, lane ID) of autonomous vehicle\n",
    "        self.s_ov = s_ov # [(relative position, velocity) * 6] of surronding vehicles   ----- why 6??\n",
    "    \n",
    "\n",
    "class State(object):\n",
    "    def __init__(self, feat_cur, feat_prev1, feat_prev2, feat_prev3):\n",
    "        self.features = [feat_cur, feat_prev1, feat_prev2, feat_prev3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward functions for MDP\n",
    "# Reward function for DRQN\n",
    "class Reward_RL(object):\n",
    "    def __init__(self):\n",
    "        self.reward_effi = 0\n",
    "        self.reward_safety = 0\n",
    "        self.reward_ter = 0\n",
    "\n",
    "    def cal_reward(self, alpha1, alpha2, s_t):\n",
    "        # Efficiency reward\n",
    "        self.reward_effi = alpha1 * (s_t[0][0][0] - 15)\n",
    "        # Safety reward\n",
    "        self.reward_safety = alpha2 * min(0, ttc - 2.7) + c_op*s_ov\n",
    "        # Terminal reward\n",
    "        if terminal == \"overtake\":\n",
    "            self.reward_ter = 10\n",
    "        elif terminal == \"collision\":\n",
    "            self.reward_ter = -10\n",
    "        else:\n",
    "            self.reward_ter = 0\n",
    "\n",
    "        \n",
    "# Reward function for safe exploration\n",
    "class Reward_MCTS(object):\n",
    "    def __init__(self, ):\n",
    "        self.r_mcts = -0.5\n",
    "        \n",
    "    def cal_reward(self, risk, a_rl, a_se):\n",
    "        if risk == 0  or a_rl == a_se:\n",
    "            self.r_mcts = 0\n",
    "        else:\n",
    "            self.r_mcts = -0.5\n",
    "\n",
    "        return self.r_mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Two-lane overtaking\n",
    "class TwoLane(object):\n",
    "    def __init__(self, action_space, n_actions, n_features, len, num_lane): # initialization\n",
    "        self.action_space = action_space\n",
    "        self.n_actions = n_actions\n",
    "        self.n_features = n_features\n",
    "        self.len = len\n",
    "        self.num_lane = num_lane\n",
    "\n",
    "\n",
    "        # Initialize state\n",
    "        s_e = (init_v_auto, 0)\n",
    "        s_ov = []\n",
    "        veh1 = (random.uniform(init_gap_AuV1[0], init_gap_AuV1[1]), random.uniform(init_v_v1[0], init_v_v1[1]))\n",
    "\n",
    "        rand = random.uniform(init_gap_AuV2[0], init_gap_AuV2[1])\n",
    "        if rand < 150:\n",
    "            veh2 = (rand, random.uniform(init_v_v2[0], init_v_v2[1]))\n",
    "        else:\n",
    "            veh2 = (150, -1)\n",
    "\n",
    "        rand = veh2[0]+random.uniform(init_gap_V2V3[0], init_gap_V2V3[1])\n",
    "        if rand < 150:\n",
    "            veh3 = (rand, veh2[1]+random.uniform(init_v_v3[0], init_v_v3[1]))\n",
    "        else:\n",
    "            veh3 = (150, -1)\n",
    "\n",
    "        s_ov.append(veh1)\n",
    "        s_ov.append(veh2)\n",
    "        s_ov.append(veh3)\n",
    "                \n",
    "\n",
    "        self.s_t = [Feature(s_e, s_ov)]\n",
    "\n",
    "        s_e_i = (0, 0)\n",
    "        s_ov_i = [(150, -1), (150, -1), (150, -1)]\n",
    "\n",
    "        self.s_t.append([Feature(s_e_i, s_ov_i) * 3]) # [feat_cur, feat_initial, feat_initial, feat_initial]\n",
    "        \n",
    "\n",
    "    def reset(self): # reset for new episode\n",
    "        s_e = (init_v_auto, 0)\n",
    "        s_ov = []\n",
    "        veh1 = (random.uniform(init_gap_AuV1[0], init_gap_AuV1[1]), random.uniform(init_v_v1[0], init_v_v1[1]))\n",
    "\n",
    "        rand = random.uniform(init_gap_AuV2[0], init_gap_AuV2[1])\n",
    "        if rand < 150:\n",
    "            veh2 = (rand, random.uniform(init_v_v2[0], init_v_v2[1]))\n",
    "        else:\n",
    "            veh2 = (150, -1)\n",
    "\n",
    "        rand = veh2[0]+random.uniform(init_gap_V2V3[0], init_gap_V2V3[1])\n",
    "        if rand < 150:\n",
    "            veh3 = (rand, veh2[1]+random.uniform(init_v_v3[0], init_v_v3[1]))\n",
    "        else:\n",
    "            veh3 = (150, -1)\n",
    "\n",
    "        s_ov.append(veh1)\n",
    "        s_ov.append(veh2)\n",
    "        s_ov.append(veh3)\n",
    "                \n",
    "\n",
    "        self.s_t = [Feature(s_e, s_ov)]\n",
    "\n",
    "        s_e_i = (0, 0)\n",
    "        s_ov_i = [(150, -1), (150, -1), (150, -1)]\n",
    "\n",
    "        self.s_t.append([Feature(s_e_i, s_ov_i) * 3])\n",
    "\n",
    "\n",
    "    def step(self, action): # state transition\n",
    "\n",
    "        # Get next feature\n",
    "        # Check lane change\n",
    "        if action[1]:\n",
    "            lane = self.s_t[0].s_e[1] or action[1] # Works only for two lane [0, 1]\n",
    "          \n",
    "        # Calculate new velocity of autonomous vehicle\n",
    "        new_v_auto = self.s_t[0].s_e[0] + action[0] * time_step\n",
    "\n",
    "        new_s_e = (new_v_auto, lane)\n",
    "        # Calculate new position and velocity for other vehicles\n",
    "        new_s_ov = []\n",
    "        \n",
    "        veh1 = (random.uniform(init_gap_AuV1[0], init_gap_AuV1[1]), random.uniform(init_v_v1[0], init_v_v1[1]))\n",
    "        # how to calculate veh2 and veh 3? -> Intelligent Driver Model\n",
    "\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe exploration\n",
    "# Risk state estimation\n",
    "# Safe policy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRQN from now on"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
